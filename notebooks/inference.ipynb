{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "(parent_folder_path, current_dir) = os.path.split(os.path.abspath(''))\n",
    "sys.path.append(parent_folder_path)\n",
    "\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\"\n",
    "\n",
    "import os\n",
    "# import pickle\n",
    "import numpy as np\n",
    "from contextlib import nullcontext\n",
    "import torch\n",
    "\n",
    "from equities.model import GPTConfig, GPT\n",
    "from equities.data_processing import itch_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT PARAMS\n",
    "# -----------------------------------------------------------------------------\n",
    "init_from = 'resume' # either 'resume' (from an out_dir) or a gpt2 variant (e.g. 'gpt2-xl')\n",
    "out_dir = parent_folder_path + '/out' # ignored if init_from is not 'resume'\n",
    "dataset = '12302019.NASDAQ_ITCH50_AAPL_message_proc.npy' # dataset to use for initial prompt\n",
    "# start = \"\\n\" # or \"<|endoftext|>\" or etc. Can also specify a file, use as: \"FILE:prompt.txt\"\n",
    "num_context_msgs = 100 # 3 # number of messages from dataset to use as context\n",
    "# num_samples = 10 # number of samples to draw\n",
    "num_samples = 1 # number of samples to draw\n",
    "# max_new_tokens = 500 # number of tokens generated in each sample\n",
    "max_new_tokens = 1 # number of tokens generated in each sample\n",
    "temperature = 0.8 # 1.0 = no change, < 1.0 = less random, > 1.0 = more random, in predictions\n",
    "top_k = 200 # retain only the top_k most likely tokens, clamp others to have 0 probability\n",
    "seed = 42\n",
    "device = 'cuda' # examples: 'cpu', 'cuda', 'cuda:0', 'cuda:1', etc.\n",
    "dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16' # 'float32' or 'bfloat16' or 'float16'\n",
    "compile = False # use PyTorch 2.0 to compile the model to be faster\n",
    "# exec(open('equities/configurator.py').read()) # overrides from command line or config file\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmul\n",
    "torch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn\n",
    "device_type = 'cuda' if 'cuda' in device else 'cpu' # for later use in torch.autocast\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 94.57M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(12515, 768)\n",
       "    (wpe): Embedding(10367, 768)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x Block(\n",
       "        (ln_1): LayerNorm()\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (c_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=False)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=12515, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "if init_from == 'resume':\n",
    "    # init from a model saved in a specific directory\n",
    "    ckpt_path = os.path.join(out_dir, 'ckpt.pt')\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "    gptconf = GPTConfig(**checkpoint['model_args'])\n",
    "    model = GPT(gptconf)\n",
    "    state_dict = checkpoint['model']\n",
    "    unwanted_prefix = '_orig_mod.'\n",
    "    for k,v in list(state_dict.items()):\n",
    "        if k.startswith(unwanted_prefix):\n",
    "            state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_raw.shape: (100, 18)\n",
      "X_raw: [[       40   7872401         1 ...     -9999     -9999     -9999]\n",
      " [       40   7872405         1 ...     -9999     -9999     -9999]\n",
      " [       40   7872421         1 ...     -9999     -9999     -9999]\n",
      " ...\n",
      " [       40   8209581         1 ...     -9999     -9999     -9999]\n",
      " [       40   7963801         4 ...     34200 240679848     -9999]\n",
      " [       40   8209581         4 ...     34200 776929875     -9999]]\n",
      "X.shape: (100, 24)\n",
      "X: [[12051  1003 12010 ...     2     2     2]\n",
      " [12051  1003 12010 ...     2     2     2]\n",
      " [12051  1003 12011 ...     2     2     2]\n",
      " ...\n",
      " [12051  1003 12011 ...     2     2     2]\n",
      " [12051  1006 12011 ...   243   682   851]\n",
      " [12051  1006 12011 ...   779   932   878]]\n",
      "decoded X: [[       40     -9999         1 ...     -9999     -9999     -9999]\n",
      " [       40     -9999         1 ...     -9999     -9999     -9999]\n",
      " [       40     -9999         1 ...     -9999     -9999     -9999]\n",
      " ...\n",
      " [       40     -9999         1 ...     -9999     -9999     -9999]\n",
      " [       40     -9999         4 ...     34200 240679848     -9999]\n",
      " [       40     -9999         4 ...     34200 776929875     -9999]]\n",
      "['ticker', 'NA_VAL', 'event_type', 'direction', 'NA_VAL', 'price', 'fill_size', 'remain_size', 'delta_t_s', 'delta_t_ns', 'time_s', 'time_ns', 'NA_VAL', 'price_ref', 'fill_size_ref', 'time_s_ref', 'time_ns_ref', 'NA_VAL']\n"
     ]
    }
   ],
   "source": [
    "# define path for sample data\n",
    "# dataset = '12302019.NASDAQ_ITCH50_AAPL_message_proc.npy'\n",
    "data_dir = os.path.join('dataset/proc/ITCH/test/', dataset)\n",
    "data_dir = parent_folder_path + '/' + data_dir\n",
    "\n",
    "# grab sample data to use as context\n",
    "context_dataset = np.load(data_dir, mmap_mode='r')\n",
    "X_raw = np.array(context_dataset[0:num_context_msgs])\n",
    "print(\"X_raw.shape:\", X_raw.shape)\n",
    "print(\"X_raw:\", X_raw)\n",
    "\n",
    "# encode the sample data\n",
    "vocab = itch_encoding.Vocab()\n",
    "X = itch_encoding.encode_msgs(X_raw, vocab.ENCODING)\n",
    "print(\"X.shape:\", X.shape)\n",
    "print(\"X:\", X)\n",
    "\n",
    "# decode the sample data (will be missing order id, price_abs, old_id, and old_price_abs)\n",
    "print(\"decoded X:\", itch_encoding.decode_msgs(X, vocab.ENCODING))\n",
    "print([ \"ticker\", \"NA_VAL\",\n",
    "        \"event_type\", \"direction\", \"NA_VAL\", \"price\", \"fill_size\", \"remain_size\",\n",
    "        \"delta_t_s\", \"delta_t_ns\", \"time_s\", \"time_ns\",\n",
    "        \"NA_VAL\", \"price_ref\", \"fill_size_ref\", \"time_s_ref\", \"time_ns_ref\", \"NA_VAL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded_tok_len: 24\n"
     ]
    }
   ],
   "source": [
    "encoded_tok_len = X.shape[1]\n",
    "print(\"encoded_tok_len:\", encoded_tok_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: torch.Size([1, 2400])\n",
      "x: tensor([[12051,  1003, 12010,  ...,   779,   932,   878]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last generated msg: 172\n",
      "---------------\n",
      "new sequence [12051, 1003, 12010, 12008, 12007, 1108, 2, 3, 18, 164, 949, 37, 203, 25, 606, 15, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 11603, 1108, 2, 3, 3, 9, 902, 37, 203, 25, 612, 914, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 12007, 1108, 2, 3, 3, 19, 785, 37, 203, 25, 629, 696, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 11577, 1108, 2, 3, 3, 13, 621, 37, 203, 25, 640, 314, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 12007, 1108, 2, 3, 3, 470, 892, 37, 203, 26, 108, 203, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 12007, 1108, 2, 3, 3, 21, 811, 37, 203, 26, 127, 11, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 11603, 1108, 2, 3, 3, 160, 127, 37, 203, 26, 284, 135, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 11577, 1108, 2, 3, 3, 23, 59, 37, 203, 26, 304, 191, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 11322, 1108, 2, 3, 3, 841, 1001, 37, 203, 27, 143, 189, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 11340, 1108, 2, 3, 3, 7, 248, 37, 203, 27, 147, 434, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1006, 12010, 12008, 11340, 1108, 1008, 3, 33, 887, 509, 37, 203, 58, 31, 940, 12008, 11340, 1108, 37, 203, 27, 147, 434, 12051, 1003, 12010, 12008, 11326, 1108, 2, 3, 3, 14, 282, 37, 203, 58, 43, 219, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 12007, 1108, 2, 3, 3, 121, 594, 37, 203, 58, 161, 810, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 12007, 1108, 2, 3, 3, 22, 251, 37, 203, 58, 181, 58, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 12007, 1308, 2, 3, 3, 118, 94, 37, 203, 58, 296, 149, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 12007, 1308, 2, 3, 3, 12, 996, 37, 203, 58, 306, 142, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 12007, 1308, 2, 3, 3, 52, 667, 37, 203, 58, 355, 806, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 12007, 1308, 2, 3, 3, 4, 262, 37, 203, 58, 357, 65, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 12007, 1092, 2, 3, 5, 523, 493, 37, 203, 60, 877, 555, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 11019, 1108, 2, 3, 3, 626, 465, 37, 203, 61, 501, 17, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 12007, 1189, 2, 3, 3, 86, 612, 37, 203, 61, 584, 626, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 12007, 1212, 2, 3, 3, 338, 443, 37, 203, 61, 920, 66, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 12007, 1164, 2, 3, 3, 746, 675, 37, 203, 62, 663, 738, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 12007, 1176, 2, 3, 4, 124, 814, 37, 203, 63, 785, 549, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 12007, 1197, 2, 3, 3, 509, 922, 37, 203, 64, 292, 468, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1006, 12010, 12008, 11326, 1108, 1008, 3, 27, 92, 342, 37, 203, 88, 381, 807, 12008, 11326, 1108, 37, 203, 58, 43, 219, 12051, 1003, 12010, 12008, 11340, 1108, 2, 3, 3, 10, 293, 37, 203, 88, 389, 97, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 12007, 1108, 2, 3, 7, 844, 880, 37, 203, 93, 230, 974, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 12007, 1108, 2, 3, 3, 22, 967, 37, 203, 93, 250, 938, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 12007, 1108, 2, 3, 45, 790, 850, 37, 203, 136, 38, 785, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 12007, 1108, 2, 3, 3, 33, 173, 37, 203, 136, 68, 955, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 11019, 1029, 2, 3, 54, 674, 759, 37, 203, 187, 740, 711, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 12007, 1013, 2, 3, 23, 725, 542, 37, 203, 208, 463, 250, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 11019, 1028, 2, 3, 18, 296, 119, 37, 203, 223, 756, 366, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 12007, 1009, 2, 3, 13, 142, 115, 37, 203, 233, 895, 478, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 11024, 1108, 2, 3, 12, 790, 376, 37, 203, 243, 682, 851, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 11024, 1108, 2, 3, 3, 4, 341, 37, 203, 243, 684, 189, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 11019, 1208, 2, 3, 3, 914, 576, 37, 203, 244, 595, 762, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 12007, 1010, 2, 3, 34, 829, 490, 37, 203, 276, 422, 249, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 11371, 1494, 2, 3, 13, 395, 740, 37, 203, 286, 814, 986, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1006, 12010, 12008, 12007, 1087, 1008, 3, 13, 913, 489, 37, 203, 297, 725, 472, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 12007, 1108, 2, 3, 41, 689, 467, 37, 203, 336, 411, 936, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 12007, 1108, 2, 3, 3, 32, 190, 37, 203, 336, 441, 123, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1006, 12010, 12008, 11019, 1028, 1008, 3, 31, 16, 972, 37, 203, 364, 455, 92, 12008, 11019, 1028, 37, 203, 223, 756, 366, 12051, 1006, 12010, 12008, 11071, 1081, 1008, 3, 9, 105, 228, 37, 203, 370, 557, 317, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1006, 12011, 12009, 11345, 1009, 1008, 3, 8, 139, 928, 37, 203, 375, 694, 242, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1006, 12011, 12009, 11070, 1508, 1008, 3, 78, 97, 763, 37, 203, 450, 788, 1002, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 11308, 1108, 2, 3, 3, 186, 252, 37, 203, 450, 972, 251, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 11307, 1108, 2, 3, 3, 5, 952, 37, 203, 450, 975, 200, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1006, 12010, 12008, 11340, 1108, 1008, 3, 115, 431, 456, 37, 203, 563, 403, 653, 12008, 11340, 1108, 37, 203, 88, 389, 97, 12051, 1003, 12010, 12008, 11308, 1108, 2, 3, 3, 19, 882, 37, 203, 563, 420, 532, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 11019, 1108, 2, 3, 3, 118, 42, 37, 203, 563, 535, 571, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1006, 12010, 12008, 12007, 1088, 1008, 3, 40, 856, 939, 37, 203, 601, 389, 507, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 11990, 1058, 2, 3, 87, 173, 437, 37, 203, 685, 559, 941, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1004, 12010, 12008, 11019, 1197, 1505, 3, 17, 592, 494, 37, 203, 700, 149, 432, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1004, 12010, 12008, 11019, 1282, 1231, 3, 5, 541, 476, 37, 203, 702, 687, 905, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 11591, 1108, 2, 3, 38, 610, 222, 37, 203, 738, 295, 124, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 12007, 1050, 2, 3, 7, 124, 960, 37, 203, 742, 417, 81, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1006, 12010, 12008, 12007, 1108, 1008, 3, 14, 170, 933, 37, 203, 753, 585, 11, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1005, 12010, 12008, 11027, 1231, 1008, 3, 28, 601, 84, 37, 203, 779, 183, 92, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1005, 12010, 12008, 11027, 1108, 1008, 3, 3, 3, 3, 37, 203, 779, 183, 92, 12008, 11019, 1108, 37, 203, 563, 535, 571, 12051, 1005, 12010, 12008, 11024, 1108, 1008, 3, 3, 3, 3, 37, 203, 779, 183, 92, 12008, 11024, 1108, 37, 203, 243, 684, 189, 12051, 1003, 12010, 12008, 11017, 1028, 2, 3, 3, 3, 3, 37, 203, 779, 183, 92, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12008, 11019, 1026, 2, 3, 3, 3, 3, 37, 203, 779, 183, 92, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 11011, 1028, 2, 3, 3, 3, 3, 37, 203, 779, 183, 92, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 11014, 1093, 2, 3, 3, 3, 3, 37, 203, 779, 183, 92, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 11013, 1010, 2, 3, 3, 3, 3, 37, 203, 779, 183, 92, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 11014, 1208, 2, 3, 3, 3, 3, 37, 203, 779, 183, 92, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 11013, 1038, 2, 3, 3, 3, 3, 37, 203, 779, 183, 92, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 11014, 1022, 2, 3, 3, 3, 3, 37, 203, 779, 183, 92, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 11013, 1026, 2, 3, 3, 3, 3, 37, 203, 779, 183, 92, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 11014, 2008, 2, 3, 3, 3, 3, 37, 203, 779, 183, 92, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 11013, 1058, 2, 3, 3, 3, 3, 37, 203, 779, 183, 92, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 11014, 1158, 2, 3, 3, 3, 3, 37, 203, 779, 183, 92, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 11013, 1010, 2, 3, 3, 3, 3, 37, 203, 779, 183, 92, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 11014, 1106, 2, 3, 3, 3, 3, 37, 203, 779, 183, 92, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 11013, 1508, 2, 3, 3, 3, 3, 37, 203, 779, 183, 92, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 11014, 1013, 2, 3, 3, 3, 3, 37, 203, 779, 183, 92, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 11013, 1013, 2, 3, 3, 3, 3, 37, 203, 779, 183, 92, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 11014, 1011, 2, 3, 3, 3, 3, 37, 203, 779, 183, 92, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 11013, 1508, 2, 3, 3, 3, 3, 37, 203, 779, 183, 92, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 11014, 1009, 2, 3, 3, 3, 3, 37, 203, 779, 183, 92, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 11016, 1011, 2, 3, 3, 3, 3, 37, 203, 779, 183, 92, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 11014, 1012, 2, 3, 3, 3, 3, 37, 203, 779, 183, 92, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 11020, 1016, 2, 3, 3, 3, 3, 37, 203, 779, 183, 92, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 11014, 1011, 2, 3, 3, 3, 3, 37, 203, 779, 183, 92, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12010, 12008, 11022, 1013, 2, 3, 3, 3, 3, 37, 203, 779, 183, 92, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 11014, 1108, 2, 3, 3, 3, 3, 37, 203, 779, 183, 92, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 11015, 1012, 2, 3, 3, 3, 3, 37, 203, 779, 183, 92, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 11016, 1032, 2, 3, 3, 3, 3, 37, 203, 779, 183, 92, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 11021, 1009, 2, 3, 3, 3, 3, 37, 203, 779, 183, 92, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 11022, 1051, 2, 3, 3, 3, 3, 37, 203, 779, 183, 92, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1003, 12011, 12009, 11028, 1058, 2, 3, 3, 413, 339, 37, 203, 779, 593, 428, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1006, 12011, 12009, 11327, 1108, 1008, 3, 3, 9, 693, 37, 203, 779, 600, 118, 12009, 11308, 1108, 37, 203, 450, 972, 251, 12051, 1006, 12011, 12009, 11028, 1058, 1008, 3, 3, 14, 605, 37, 203, 779, 611, 720, 12009, 11028, 1058, 37, 203, 779, 593, 428, 12051, 1003, 12011, 12009, 11300, 1108, 2, 3, 3, 7, 444, 37, 203, 779, 616, 161, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1006, 12011, 12009, 11341, 1108, 1008, 3, 3, 314, 229, 37, 203, 779, 927, 387, 12009, 11322, 1108, 37, 203, 27, 143, 189, 12051, 1003, 12011, 12009, 11316, 1108, 2, 3, 3, 8, 494, 37, 203, 779, 932, 878, 2, 2, 2, 2, 2, 2, 2, 2, 12051, 1006, 12011, 12009, 11043, 1108, 1008, 3, 3, 24, 731, 37, 203, 779, 954, 606, 12009, 11024, 1108, 37, 203, 243, 682, 851, 12051, 1006, 12011, 12009, 11316, 1108, 1008, 3, 3, 92, 266, 37, 203, 780, 43, 869, 12009, 11316, 1108, 37, 203, 779, 932, 878, 12051, 1006, 12011, 12009, 11121, 1012, 1008, 3, 3, 113, 82, 37, 203, 780, 83, 722, 12009, 11124, 1012, 37, 203, 778, 218, 172]\n"
     ]
    }
   ],
   "source": [
    "# prepare context tensor\n",
    "x = (torch.tensor(X.reshape(-1), dtype=torch.long, device=device)[None, ...])\n",
    "print(\"x.shape:\", x.shape)\n",
    "print(\"x:\", x)\n",
    "\n",
    "# run generation\n",
    "with torch.no_grad():\n",
    "    with ctx:\n",
    "        for k in range(num_samples):\n",
    "            # y = model.generate(x, max_new_tokens, temperature=temperature, top_k=top_k)\n",
    "            y = model.generate(x, max_new_tokens*encoded_tok_len, temperature=temperature, top_k=top_k)\n",
    "            # print(decode(y[0].tolist()))\n",
    "            print(\"last generated msg:\", y[0][-1].tolist())\n",
    "            # print(y[0].tolist())\n",
    "            print('---------------')\n",
    "        print(\"new sequence\", y[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last generated msg: [12051, 1006, 12011, 12009, 11121, 1012, 1008, 3, 3, 113, 82, 37, 203, 780, 83, 722, 12009, 11124, 1012, 37, 203, 778, 218, 172]\n",
      "y: tensor([[12051,  1003, 12010,  ...,   778,   218,   172]], device='cuda:0')\n",
      "[       40     -9999         4         1     -9999       113         4\n",
      "         0         0    110079     34200 777080719     -9999       116\n",
      "         4     34200 775215169     -9999]\n",
      "['ticker', 'NA_VAL', 'event_type', 'direction', 'NA_VAL', 'price', 'fill_size', 'remain_size', 'delta_t_s', 'delta_t_ns', 'time_s', 'time_ns', 'NA_VAL', 'price_ref', 'fill_size_ref', 'time_s_ref', 'time_ns_ref', 'NA_VAL']\n"
     ]
    }
   ],
   "source": [
    "# print the last message in the generated sequence\n",
    "print(\"last generated msg:\", y[0][-24:].tolist())\n",
    "\n",
    "# print(y[0].tolist())\n",
    "print(\"y:\", y)\n",
    "\n",
    "# decode the generated sequence\n",
    "# print(\"decoded y:\", itch_encoding.decode_msg(y[0][-24:].tolist(), vocab.ENCODING))\n",
    "# print(\"decoded msg:\", itch_encoding.decode_msg(np.array(y[0][-24:].tolist()), vocab.ENCODING))\n",
    "decoded_msg = itch_encoding.decode_msg(np.array(y[0][-24:].tolist()), vocab.ENCODING)\n",
    "print(decoded_msg)\n",
    "print([ \"ticker\", \"NA_VAL\",\n",
    "        \"event_type\", \"direction\", \"NA_VAL\", \"price\", \"fill_size\", \"remain_size\",\n",
    "        \"delta_t_s\", \"delta_t_ns\", \"time_s\", \"time_ns\",\n",
    "        \"NA_VAL\", \"price_ref\", \"fill_size_ref\", \"time_s_ref\", \"time_ns_ref\", \"NA_VAL\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_true: [[       40   7872401         1 ...     -9999     -9999     -9999]\n",
      " [       40   7872405         1 ...     -9999     -9999     -9999]\n",
      " [       40   7872421         1 ...     -9999     -9999     -9999]\n",
      " ...\n",
      " [       40   7963801         4 ...     34200 240679848     -9999]\n",
      " [       40   8209581         4 ...     34200 776929875     -9999]\n",
      " [       40   8209645         1 ...     -9999     -9999     -9999]]\n",
      "true last msg: [       40   8209645         1         1     29277       333       100\n",
      "     -9999         0      4786     34200 777045652     -9999     -9999\n",
      "     -9999     -9999     -9999     -9999]\n"
     ]
    }
   ],
   "source": [
    "X_true = np.array(context_dataset[0:num_context_msgs+max_new_tokens])\n",
    "print(\"X_true:\", X_true)\n",
    "\n",
    "print(\"true last msg:\", X_true[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoded msg: [       40     -9999         4         1     -9999       113         4\n",
      "         0         0    110079     34200 777080719     -9999       116\n",
      "         4     34200 775215169     -9999]\n",
      "predicted symbol: 40\n",
      "predicted event type: 4\n",
      "predicted price: 113\n",
      "predicted fill size: 4\n",
      "predicted remain size: 0\n",
      "predicted time: 34200 777080719\n",
      "predicted price ref: 116\n",
      "predicted fill size ref: 4\n",
      "predicted time ref: 34200 775215169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([       40,     -9999,         4,         1,     -9999,       113,\n",
       "               4,         0,         0,    110079,     34200, 777080719,\n",
       "           -9999,       116,         4,     34200, 775215169,     -9999])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"decoded msg:\", decoded_msg)\n",
    "print(\"predicted symbol:\", decoded_msg[0])\n",
    "print(\"predicted event type:\", decoded_msg[2])\n",
    "print(\"predicted price:\", decoded_msg[5])\n",
    "print(\"predicted fill size:\", decoded_msg[6])\n",
    "print(\"predicted remain size:\", decoded_msg[7])\n",
    "print(\"predicted time:\", decoded_msg[10], decoded_msg[11])\n",
    "print(\"predicted price ref:\", decoded_msg[13])\n",
    "print(\"predicted fill size ref:\", decoded_msg[14])\n",
    "print(\"predicted time ref:\", decoded_msg[15], decoded_msg[16])\n",
    "\n",
    "decoded_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MarketSimT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
